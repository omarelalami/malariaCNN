{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LwQw8zpdxUjk",
    "outputId": "75cfc0ac-a248-4c20-a647-5652283bac27"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Spécifiez le chemin où se trouvent vos données\n",
    "data_dir = 'malaria_hematie_dataset'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "D3_nqY3FneVn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 18:07:47.264244: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('/home/sagemaker-user/malaria_hematie_dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/home/sagemaker-user')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd2uYuzQ5W1I",
    "outputId": "3ea46b13-e4d2-4541-e40b-48c673943397"
   },
   "outputs": [],
   "source": [
    "# Spécifiez le chemin où se trouvent vos données\n",
    "data_dir = 'malaria_hematie_dataset'\n",
    "categories = ['parasitized', 'uninfected']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kHTqo615YCb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "batch_size = 32  # Définir la taille du lot\n",
    "\n",
    "# Parcourir toutes les catégories\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category)\n",
    "    images_in_category = os.listdir(category_path)\n",
    "    \n",
    "    # Parcourir les images de chaque catégorie\n",
    "    for i in range(0, len(images_in_category), batch_size):\n",
    "        batch_images = []\n",
    "        for img_name in images_in_category[i:i+batch_size]:\n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = image.resize((128, 128))  # Redimensionner les images si nécessaire\n",
    "            batch_images.append(np.array(image))\n",
    "            labels.append(category)\n",
    "        data.append(np.array(batch_images))\n",
    "\n",
    "data = np.concatenate(data, axis=0)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VIHrjEIAvHVK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Normaliser les images\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Normaliser les images\n",
    "data = data / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSfoyttnzcQk"
   },
   "outputs": [],
   "source": [
    "# Encoder les labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_G90cxvVz1H_"
   },
   "outputs": [],
   "source": [
    "# Faire de la data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "Mf9srpZLz3zh",
    "outputId": "8c91e33d-37af-450b-e9a1-d049d4b99faa"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for X_batch, y_batch in datagen.flow(data, labels_encoded, batch_size=9):\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVtAu5-g0LjK"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "# Callback pour l'arrêt précoce\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Callback pour la réduction du taux d'apprentissage\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpW3qdb6rro1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcFcbEsT17pr"
   },
   "outputs": [],
   "source": [
    "model_scratch = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_scratch.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vouKsTyD0OFC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "# Charger le modèle VGG16 pré-entraîné sans les poids\n",
    "base_model_vgg16 = VGG16(weights=None, include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Ajouter des couches de classification\n",
    "x = base_model_vgg16.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Définir le modèle complet\n",
    "model_vgg16 = Model(inputs=base_model_vgg16.input, outputs=predictions)\n",
    "\n",
    "# Geler les couches convolutionnelles de VGG16\n",
    "for layer in base_model_vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_vgg16.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxD0A0if0UmA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "# Charger le modèle ResNet50 pré-entraîné sans les poids\n",
    "base_model_resnet50 = ResNet50(weights=None, include_top=False, input_shape=(128, 128, 3))\n",
    "\n",
    "# Ajouter des couches de classification\n",
    "x = base_model_resnet50.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Définir le modèle complet\n",
    "model_resnet50 = Model(inputs=base_model_resnet50.input, outputs=predictions)\n",
    "\n",
    "# Geler les couches convolutionnelles de ResNet50\n",
    "for layer in base_model_resnet50.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_resnet50.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lz4Y62_B05Ro"
   },
   "outputs": [],
   "source": [
    "# Entraîner le modèle from scratch\n",
    "history_scratch = model_scratch.fit(data, labels_encoded, epochs=50, validation_split=0.2, batch_size=32, callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Entraîner le modèle VGG16\n",
    "history_vgg16 = model_vgg16.fit(data, labels_encoded, epochs=50, validation_split=0.2, batch_size=32, callbacks=[early_stopping, reduce_lr], verbose=2)\n",
    "\n",
    "# Entraîner le modèle ResNet50\n",
    "history_resnet50 = model_resnet50.fit(data, labels_encoded, epochs=50, validation_split=0.2, batch_size=32, callbacks=[early_stopping, reduce_lr], verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6RRZNDo2C9B"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Prédire les classes pour chaque modèle\n",
    "predictions_scratch = model_scratch.predict(test_data)\n",
    "predictions_vgg16 = model_vgg16.predict(test_data)\n",
    "predictions_resnet50 = model_resnet50.predict(test_data)\n",
    "\n",
    "# Convertir les prédictions en classes (0 ou 1)\n",
    "predictions_scratch_classes = (predictions_scratch > 0.5).astype(int)\n",
    "predictions_vgg16_classes = (predictions_vgg16 > 0.5).astype(int)\n",
    "predictions_resnet50_classes = (predictions_resnet50 > 0.5).astype(int)\n",
    "\n",
    "# Calculer la matrice de confusion pour chaque modèle\n",
    "confusion_scratch = confusion_matrix(test_labels, predictions_scratch_classes)\n",
    "confusion_vgg16 = confusion_matrix(test_labels, predictions_vgg16_classes)\n",
    "confusion_resnet50 = confusion_matrix(test_labels, predictions_resnet50_classes)\n",
    "\n",
    "print(\"Matrice de Confusion - Modèle From Scratch :\\n\", confusion_scratch)\n",
    "print(\"\\nMatrice de Confusion - Modèle VGG16 :\\n\", confusion_vgg16)\n",
    "print(\"\\nMatrice de Confusion - Modèle ResNet50 :\\n\", confusion_resnet50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LnnzAtCwfk_"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# Définir une fonction pour calculer toutes les métriques\n",
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Calculer les métriques pour chaque modèle\n",
    "accuracy_scratch, precision_scratch, recall_scratch, f1_scratch = calculate_metrics(test_labels, predictions_scratch_classes)\n",
    "accuracy_vgg16, precision_vgg16, recall_vgg16, f1_vgg16 = calculate_metrics(test_labels, predictions_vgg16_classes)\n",
    "accuracy_resnet50, precision_resnet50, recall_resnet50, f1_resnet50 = calculate_metrics(test_labels, predictions_resnet50_classes)\n",
    "\n",
    "print(\"Métriques de Performance - Modèle From Scratch :\")\n",
    "print(\"Accuracy : {:.2f}\".format(accuracy_scratch))\n",
    "print(\"Precision : {:.2f}\".format(precision_scratch))\n",
    "print(\"Recall : {:.2f}\".format(recall_scratch))\n",
    "print(\"F1-Score : {:.2f}\".format(f1_scratch))\n",
    "\n",
    "print(\"\\nMétriques de Performance - Modèle VGG16 :\")\n",
    "print(\"Accuracy : {:.2f}\".format(accuracy_vgg16))\n",
    "print(\"Precision : {:.2f}\".format(precision_vgg16))\n",
    "print(\"Recall : {:.2f}\".format(recall_vgg16))\n",
    "print(\"F1-Score : {:.2f}\".format(f1_vgg16))\n",
    "\n",
    "print(\"\\nMétriques de Performance - Modèle ResNet50 :\")\n",
    "print(\"Accuracy : {:.2f}\".format(accuracy_resnet50))\n",
    "print(\"Precision : {:.2f}\".format(precision_resnet50))\n",
    "print(\"Recall : {:.2f}\".format(recall_resnet50))\n",
    "print(\"F1-Score : {:.2f}\".format(f1_resnet50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhsPsUUh2Vat"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculer les courbes ROC pour chaque modèle\n",
    "fpr_scratch, tpr_scratch, _ = roc_curve(test_labels, predictions_scratch)\n",
    "fpr_vgg16, tpr_vgg16, _ = roc_curve(test_labels, predictions_vgg16)\n",
    "fpr_resnet50, tpr_resnet50, _ = roc_curve(test_labels, predictions_resnet50)\n",
    "\n",
    "# Calculer l'AUC pour chaque modèle\n",
    "auc_scratch = auc(fpr_scratch, tpr_scratch)\n",
    "auc_vgg16 = auc(fpr_vgg16, tpr_vgg16)\n",
    "auc_resnet50 = auc(fpr_resnet50, tpr_resnet50)\n",
    "\n",
    "# Afficher les courbes ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_scratch, tpr_scratch, label='Modèle From Scratch (AUC = {:.2f})'.format(auc_scratch))\n",
    "plt.plot(fpr_vgg16, tpr_vgg16, label='Modèle VGG16 (AUC = {:.2f})'.format(auc_vgg16))\n",
    "plt.plot(fpr_resnet50, tpr_resnet50, label='Modèle ResNet50 (AUC = {:.2f})'.format(auc_resnet50))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Courbe ROC')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5038068,
     "sourceId": 8453455,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
